{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f1b64c",
   "metadata": {},
   "source": [
    "# Building and Visualizing word frequencies\n",
    "\n",
    "In this lab, we focus on the `build_freqs()` helper function and visualizing a dataset fed into it. In out goal of tweet sentiment analysis, this function will build a dictionary where we can lookup how many times a word appears in the lists of positive or negative tweets. This will be very helpful when extracting the features of the dataset in the week's programming assignment. Let's see how this function is implemented under the hood in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d7a53",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the required linraries for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bc797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample twitter dataset\n",
    "import matplotlib.pyplot as plt            # visualizing libray\n",
    "import numpy as np                         # library for scientific computing, matrix operations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bb323",
   "metadata": {},
   "source": [
    "**Import some helper functions that we provided in the utils.py file:**\n",
    "\n",
    "- `process_tweet()`: Cleans the text, tokenizes it into separate words, removes stopwords, and converts words to stems.\n",
    "- `build_freqs()`: This counts how often a word in the 'corpus' (the entire set of tweets) was associated with a positive label `1` or a negative label `0`. It then builds the `freqs` dictionary, where each key is a `(word, label)` tuple, and the value is the count of its frequency within the corpus of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c41e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Ashish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the twitter_samples dataset, run the line below if running on a local machine\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb264f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ashish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download the stopwords from the nltk corpus\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# import our convernience functions\n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e313c25",
   "metadata": {},
   "source": [
    "## Load the NLTK sample dataset\n",
    "As in the previous lab, we will be using the [Twitter dataset from NLTK](http://www.nltk.org/howto/twitter.html#Using-a-Tweet-Corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfea1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  10000\n"
     ]
    }
   ],
   "source": [
    "# Select the lists of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
    "tweets = all_positive_tweets + all_negative_tweets\n",
    "\n",
    "# let's see how many tweets we have\n",
    "print('Number of tweets: ', len(tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7356a03",
   "metadata": {},
   "source": [
    "Next we will build a label array that matches the sentiments of our tweets. This data type works pretty much like a regular list but is optimized for computations and manipulation. The `labels` array will be composed of 10000 elements. The first 5000 will be filled with `1` labels denoting positive sentiments, and the next 5000 will be `0` labels denoting the opposite. We can do this easily with a series of operations provided by the `numpy` library:\n",
    "\n",
    "- `np.ones()` - create an array of 1's\n",
    "- `np.zeros()` - create an array of 0's\n",
    "- `np.append()` - concatenate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38b307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  10000\n",
      "shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# make a numpy array representing labels of the tweets\n",
    "labels = np.append(np.ones(len(all_positive_tweets)),\n",
    "                  np.zeros(len(all_negative_tweets)))\n",
    "\n",
    "print('size: ', labels.size)\n",
    "print('shape: ',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ca7ae",
   "metadata": {},
   "source": [
    "## Dictionaries\n",
    "In python, a dictionary is a mutable and indexed collection, but unordered. It stores items as key-value pairs and uses [hash tables](https://en.wikipedia.org/wiki/Hash_table) underneath to allow practically constant time lookups. In NLP, dictionaries are essential because it enables fast retrieval of items or containment checks even with thousands of entries in the collection.\n",
    "\n",
    "**How do hash tables ensure constant time look-ups?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b6bb3",
   "metadata": {},
   "source": [
    "### Definition\n",
    "A dictionary in python is declared using curly brackets. Look at the next example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22ea6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'key1': 1, 'key2': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b272062",
   "metadata": {},
   "source": [
    "The former line defines a dictionary with two entries. Keys and values can be almost any type ([with a few restriction on keys](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)), and in this case, we used strings. We can also use floats, integers, tuples, etc.\n",
    "\n",
    "### Adding or editing entries\n",
    "New entries can be inserted into dictionaries using square brackets. If the dictionary already containes the specified key, its value is overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66cfba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key1': 0, 'key2': 2, 'key3': -5}\n"
     ]
    }
   ],
   "source": [
    "# Add a new entry\n",
    "dictionary['key3'] = -5\n",
    "\n",
    "# Overwrite the value of key1\n",
    "dictionary['key1'] = 0\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17828efd",
   "metadata": {},
   "source": [
    "### Assessing values and lookup keys\n",
    "Performing dictionary lookups and retrieval are common tasks in NLP. There are two ways to do this:\n",
    "- Using square bracket notation: This form is allowed if the lookup key is in the dictionary. It produces and error otherwise.\n",
    "- Using the [get()](https://docs.python.org/3/library/stdtypes.html#dict.get) method: This allows us to set a default value if the dictionary key does not exist.\n",
    "\n",
    "Let us see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2c8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Square bracket lookup when the key exist\n",
    "print(dictionary['key2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac929325",
   "metadata": {},
   "source": [
    "However, if the key is missing, the operation produces an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ece15789",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# The output of this line is intended to produce a KeyError\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key8'"
     ]
    }
   ],
   "source": [
    "# The output of this line is intended to produce a KeyError\n",
    "print(dictionary['key8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3008c3d",
   "metadata": {},
   "source": [
    "When using a square bracket lookup, it is common to use an if-else block to check for containment first (with the keyword `in`) before getting the item. On the other hand, you can use the `.get()` method if you want to set a default value when the key is not found. Let's compare these in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93fc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prints a value\n",
    "if 'key1' in dictionary:\n",
    "    print(\"item found: \", dictionary['key1'])\n",
    "else:\n",
    "    print('key1 is not defined')\n",
    "\n",
    "# Same as what you get with get\n",
    "print(\"item found: \", dictionary.get('key1', -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449021f",
   "metadata": {},
   "source": [
    "## Word frequency dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6832cf",
   "metadata": {},
   "source": [
    "Now that we know the building blocks, let's finally take a look at the **build_freqs()** function in **utils.py**. This is the function that creates the dictionary containing the word counts from each corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8f256",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1    \n",
    "    return freqs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e63065",
   "metadata": {},
   "source": [
    "You can also do the for loop like this to make it a bit more compact:\n",
    "\n",
    "```python\n",
    "for y, tweet in zip(yslist, tweets):\n",
    "    for word in process_tweet(tweet):\n",
    "        pair = (word, y)\n",
    "        freqs[pair] = freqs.get(pair, 0) + 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31bab9",
   "metadata": {},
   "source": [
    "As shown above, each key is a 2-element tuple containing a `(word, y)` pair. The `word` is an element in a processes tweet while `y` is an integer representing the corpus: `1` for the positive tweets and `0` for the negative tweets. The value associated with this key is the number of times that word appears in the specified corpus. For example:\n",
    "\n",
    "``` \n",
    "# \"folowfriday\" appears 25 times in the positive tweets\n",
    "('followfriday', 1.0): 25\n",
    "\n",
    "# \"shame\" appears 19 times in the negative tweets\n",
    "'shame', 0.0): 19 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02829668",
   "metadata": {},
   "source": [
    "Now, it is time to use the dictionary returned by the `build_freqs()` function. First, let us feed our `tweets` and `labels` lists then print a basic report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be765b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(tweets, labels)\n",
    "\n",
    "# chack data type\n",
    "print(f'type(freqs) = {type(freqs)}')\n",
    "\n",
    "# check length of the dictionary\n",
    "print(f'len(freqs) = {len(freqs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b568bbab",
   "metadata": {},
   "source": [
    "Now print the frequency of each word depending on the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451d96dc",
   "metadata": {},
   "source": [
    "Unfortunately, this does not help much to understand the data. It would be better to visualize this output to gain better insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb8ff0",
   "metadata": {},
   "source": [
    "## Table of word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa8ca3",
   "metadata": {},
   "source": [
    "We will select a set of words that we would like to visualise. It is better to store this temporary information in a table that is very easy to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some words to appear in the report. \n",
    "# we will assume that each word is unique (i.e no duplicates)\n",
    "keys = ['happi', 'merri', 'nice', 'good', 'bad', 'sad', 'mad', 'best', 'pretti',\n",
    "        '‚ù§', ':)', ':(', 'üòí', 'üò¨', 'üòÑ', 'üòç', '‚ôõ',\n",
    "        'song', 'idea', 'power', 'play', 'magnific']\n",
    "\n",
    "# list representing our table of word counts.\n",
    "# each element consists of a sublist with this pattern: [<word>, <positive_count>, <negative_count>]\n",
    "data = []\n",
    "\n",
    "# loop through our selected words:\n",
    "for word in keys:\n",
    "    \n",
    "    # initialize positive and negative counts\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    \n",
    "    # retrieve number of positive counts\n",
    "    if (word, 1) in freqs:\n",
    "        pos = freqs[(word,1)]\n",
    "        \n",
    "    # retrieve number of negative counts\n",
    "    if (word, 0) in freqs:\n",
    "        neg = freqs[(word,0)]\n",
    "        \n",
    "    # append the word counts to the table\n",
    "    data.append([word, pos, neg])\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb72d97",
   "metadata": {},
   "source": [
    "We can then use a scatter plot to inspect this table visually. Instead of plotting the raw counts, we will plot it in the logarithmic scale to take into account the wide discrepancies between the raw counts (e.g. `:)` has 3568 counts in the positive while only 2 in the negative). The red line marks the boundary between positive and negatice areas. Words close to the red line can be classified as neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "\n",
    "# convert positive raw counts to logarithmic scale. we add 1 to avoid log(0)\n",
    "x = np.log([x[1] + 1 for x in data])\n",
    "\n",
    "# do the same for the negative counts\n",
    "y = np.log([x[2] + 1 for x in data])\n",
    "\n",
    "# plotting a dot for eachc pair of words\n",
    "ax.scatter(x, y)\n",
    "\n",
    "# assign axis labels\n",
    "plt.xlabel(\"Log Positive Count\")\n",
    "plt.ylabel(\"Log Negative Count\")\n",
    "\n",
    "# Add the word as label at the same position as you added the points before\n",
    "for i in range(0, len(data)):\n",
    "    ax.annotate(data[i][0], (x[i], y[i]), fontsize=12)\n",
    "    \n",
    "ax.plot([0, 9], [0, 9], color='red') # Plot the red line that divides the 2 areas.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67594f4",
   "metadata": {},
   "source": [
    "This chart is straigtforward to interpret. It shows that emotions `:)` and `:(` are very important for sentiment analysis. Thus, we should not let preprocessing steps get rid of these symbols!\n",
    "\n",
    "Furthermore, what us the meaning of the crown symbol? It seems to be very negative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea342d",
   "metadata": {},
   "source": [
    "### That's all for this lab! We've seen how to build a word frequency dictionary and this will come in handy when extracting the features of a list of tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
